{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4487f05e-e428-41d5-831c-aa4d248b11cc",
   "metadata": {},
   "source": [
    "# Tokenisation avec les langages de programmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86dcd35-deab-4e01-a0c9-8185a1fbaffe",
   "metadata": {},
   "source": [
    "Nous avons plus haut présenté des utilitaires comme outils de segmentation en les détournant de leurs usages habituels. Pour cette raison, certaines tâches se révéleront assez difficiles à réaliser, notamment pour les langues qui ne reposent pas sur des motifs de séparation réguliers. Pour celles-ci, il se révélera indispensable d’installer des outils spécifiques, parmi lesquelles nous pouvons citer *OpenCC*, *ZPar* ou encore *Stanford NLP Toolkit*.\n",
    "\n",
    "Dans la pratique, il est plus courant de recourir à des langages de programmation pour lesquels il existe des bibliothèques qui prennent en charge les cas spécifiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950095ee-91b4-42bf-b972-f666dff7b07b",
   "metadata": {},
   "source": [
    "## Perl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae1a4e-53c1-421b-8155-128a734731a2",
   "metadata": {},
   "source": [
    "Perl est un langage de programmation qui s’inspire des langages de scripts comme `sed` et `awk` et qui prend en charge les expressions rationnelles, ce qui le rend très efficace pour manipuler des séquences de textes.\n",
    "\n",
    "Un exemple de tokénisateur en Perl (*utf8-tokenize.perl*) est fourni avec la distribution de [*TreeTagger*](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808d901-a4ea-48b8-94dc-328aaeb2d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"A Lannister always pays his debts.\" \\\n",
    "  | perl ./scripts/utf8-tokenize.perl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c330e4-1458-4aea-9c08-cd9c2c0eca28",
   "metadata": {},
   "source": [
    "L’algorithme par défaut est prévu pour une segmentation sur l’espace. Des options permettent d’activer des comportements différenciés pour certaines langues :\n",
    "\n",
    "- `-e` : pour l’anglais ;\n",
    "- `-f` : pour le français ;\n",
    "- `-i` : pour l’italien ;\n",
    "- `-z` : pour le galicien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490448b-dc99-4d9c-9f8b-069a067e1ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"C’est aujourd’hui ton rendez-vous chez l’ostéopathe ?\" \\\n",
    "  | perl ./scripts/utf8-tokenize.perl -f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec3c05-b1ac-411b-b442-c2bb7378f95b",
   "metadata": {},
   "source": [
    "La commande considère correctement *aujourd’hui* comme un seul mot quand *rendez-vous* a été séparé en deux. Il est possible de lui transmettre un fichier pour gérer certaines spécificités du français avec l’option `-a` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca179a-b85e-4c08-a103-419d2751d6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"C’est aujourd’hui ton rendez-vous chez l’ostéopathe ?\" \\\n",
    "  | perl ./scripts/utf8-tokenize.perl -f -a ./files/french-abbreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f90c9-4d34-4ab9-906e-9bcc889d43e7",
   "metadata": {},
   "source": [
    "Le fichier *french-abbreviations*, consistant en une simple liste de mots, ne doit être constitué qu’en connaissance de cause, c’est-à-dire après analyse des erreurs résiduelles du tokénisateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca29c3c9-6c11-4bb6-b3c3-b2c5c71f4f87",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64285d-8f61-4ce8-9db7-ec87c2314fde",
   "metadata": {},
   "source": [
    "Le langage le plus populaire actuellement dispose de nombreux outils développés pour le TAL :\n",
    "\n",
    "- *Stanza* : Bibliothèque de traitement du langage naturel développée par Stanford, spécialisée dans l’analyse syntaxique et la reconnaissance d’entités nommées. Elle prend en charge plus de 70 langues, dont l’anglais, le français, l’espagnol, l’allemand, l’italien, le chinois, etc.\n",
    "- *NLTK* : La bibliothèque de référence pour l’enseignement du TAL, elle propose des outils pour la tokenisation, l’étiquetage et l’analyse grammaticale. Prévue initialement pour l’anglais, elle supporte dans une moindre mesure des outils pour le français, l’espagnol et l’allemand. Pour l’employer avec d’autres langues, il sera nécessaire d’installer d’autres ressources.\n",
    "- *spaCy* : Une bibliothèque performante pour le traitement rapide de grandes quantités de texte, avec des fonctionnalités avancées de traitement syntaxique et de modélisation de textes. Elle supporte une large gamme de langues, dont l’anglais, le français, l’allemand, l’espagnol, l’italien, le néerlandais, etc.\n",
    "\n",
    "Pour des tâches de segmentation basées sur l’espace, n’importe laquelle de ces bibliothèques fera l’affaire, mais dès lors que l’on touche à des écritures sans espace, comme certaines langues asiatiques, *Stanza* devient le choix par défaut à moins d’installer d’autres ressources comme *jieba* pour le chinois ou *MeCab* pour le japonais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72ec81f-386d-4f7c-b384-d75bf5a8d420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
