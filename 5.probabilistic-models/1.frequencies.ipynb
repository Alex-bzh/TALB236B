{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4430eb07-7567-4ea4-8b8a-fc6300311567",
   "metadata": {},
   "source": [
    "# Calculer des fréquences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbd1c5-366a-4e80-8daf-31d4607a27a6",
   "metadata": {},
   "source": [
    "Qu’il soit sobre (*Small Language Model*), volumineux (*Large Language Model*) ou prévu pour un domaine particulier (*Specialized Language Model*), un modèle de langage est une représentation statistique de la distribution des symboles d’une langue (lettres, phonèmes, mots…) en vue d’effectuer des prédictions. En se basant par exemple sur la fréquence d’apparition des lettres dans un corpus, il est tout à fait envisageable de générer du texte. Ou plutôt une collection de lettres. Des outils supplémentaires peuvent être intégrés au modèle, comme un lexique, ou une distribution de la longueur des mots et des phrases dans un texte.\n",
    "\n",
    "La limite principale d’un modèle de langage est qu’il est incapable de rendre compte d’une langue, tout au plus de son état à un certain moment donné en vue des paramètres initiaux qui lui ont été fournis. Il repose fondamentalement sur un corpus, qui lui-même est une extraction, et reproduira ses biais. Si votre corpus contient *La montagne de l’âme* de Gao Xingjian, il risque de donner trop d’importance aux formes conjuguées des verbes à la deuxième personne du singulier. Et si vous incluez l’ensemble du contenu d’Internet, qui lui-même est de plus en plus alimenté par des IA génératives, vous ne manquerez pas de véhiculer ses fictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95c615-f02c-435c-8698-aba1923e1727",
   "metadata": {},
   "source": [
    "## Définitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d704c946-71fb-44c8-8893-337c3dd09435",
   "metadata": {},
   "source": [
    "**Occurrence :** Une occurrence désigne la survenue d’un événement dans le temps ou dans l’espace. En linguistique, le terme fait référence à l’apparition d’un mot dans une phrase, d’une lettre dans un mot, d’un morphème, ou d’un trait spécifique. Au pluriel, il est utilisé pour compter le nombre d’apparitions d’un phénomène donné.\n",
    "\n",
    "**Nombre d’apparitions :** Le nombre d’apparitions correspond au décompte exact d’un événement, autrement dit, à l’effectif total des occurrences observées.\n",
    "\n",
    "**Fréquence :** La notion est souvent liée à celle d’occurrence et peut être exprimée de deux manières :\n",
    "\n",
    "  - **La fréquence absolue :** nombre total d’occurrences d’un événement dans un corpus (p. ex. : la fréquence d’occurrences de la lettre *e* dans le verbe *vole* est de 1).\n",
    "  - **La fréquence relative :** Rapport entre la fréquence absolue d’un événement et l’effectif total de l’ensemble. Elle se situe dans l’intervalle $[0,1]$ et peut être exprimée en pourcentage (p. ex. : la fréquence relative de la lettre e dans vole est $\\frac{1}{4}$, soit 0,25 ou 25 %).\n",
    "\n",
    "**Distribution de fréquence :** Répartition des fréquences d’occurrences d’un ou plusieurs phénomènes dans un corpus, souvent visualisée sous forme de tableaux, graphiques ou histogrammes.\n",
    "\n",
    "**Mot-forme :** Représentation graphique d’un mot tel qu’il apparaît dans un texte ou un corpus, sans distinction de variations grammaticales (p. ex. : *mange*, *manges* et *mangerons* sont des mots-formes différents).\n",
    "\n",
    "**Lemme :** Forme canonique d’un mot utilisée comme entrée principale dans un dictionnaire ou un lexique (p. ex. : *manger* est le lemme des mots-formes *mange*, *manges* et *mangerons*).\n",
    "\n",
    "**Type :** En linguistique et en analyse textuelle, un type désigne une unité lexicale unique, abstraite, considérée sans prendre en compte ses occurrences spécifiques dans un texte. Par exemple, dans la phrase « Le chat mange le poisson », les types sont *le*, *chat*, *mange* et *poisson*.\n",
    "\n",
    "**Token :** Un token désigne chaque occurrence concrète d’un type dans un texte. On dénombre par exemple cinq tokens dans la phrase « Le chat mange le poisson »."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c48c024-a0b1-4535-88d4-92fd80ecbbc7",
   "metadata": {},
   "source": [
    "## Aperçu de la difficulté de la tâche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcb877b-a10c-4c64-82b5-b771f0a75186",
   "metadata": {},
   "source": [
    "### Compter des occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e152f7b6-9d8b-49a2-967c-24728921a3ec",
   "metadata": {},
   "source": [
    "L’opération revient à subdiviser un objet en éléments et à compter le nombre de fois où chaque élément apparaît. Prenons une liste d’entiers entre 0 et 10 et calculons le nombre de fois où apparaît le nombre 9 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb52b0-9ae5-4aab-baa9-0cb8891f200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"5 8 1 3 6 7 9 9 7 3\" | grep -o 9 | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490d6b6-3385-48c5-a4c4-603d67381835",
   "metadata": {},
   "source": [
    "Où :\n",
    "\n",
    "- L’option `-o` de `grep` permet d’extraire chaque occurrence du motif sur une ligne distincte\n",
    "- La commande `wc -l` compte le nombre de lignes.\n",
    "\n",
    "On peut réaliser une opération similaire en comptabilisant les apparitions de la lettre *e* dans une phrase :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dffea9-b114-41d3-b2ba-86f76dddfcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"En pratique, un pêcheur pêche avec une canne.\" \\\n",
    "| grep -o e | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd321872-5506-43c0-87b5-0e6760fc449c",
   "metadata": {},
   "source": [
    "L’informatique dissocie par défaut le caractère *e* de ses versions accentuée *ê* et majuscule *E*. Il est heureusement possible de jouer sur le motif transmis à la commande `grep` pour améliorer le résultat :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4cc80-e271-422f-8ef1-9011e7ff6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"En pratique, un pêcheur pêche avec une canne.\" \\\n",
    "| grep -o \"[eêE]\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b01b17-509b-4e0b-9ff6-2a225411153b",
   "metadata": {},
   "source": [
    "Une version encore simplifiée fait appel à l’option `-i` pour rendre l’expression rationnelle insensible à la casse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d1484-bb64-494d-8c00-0db8c1c78d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"En pratique, un pêcheur pêche avec une canne.\" \\\n",
    "| grep -oi \"[eê]\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300375bc-74a5-45f4-bcea-163542ef5d4c",
   "metadata": {},
   "source": [
    "### Normaliser avec la translittération"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343c306-86d3-4c44-a4f6-b0be0549847c",
   "metadata": {},
   "source": [
    "Le cas précédent nécessite encore de faire l’inventaire de toutes les manières de représenter la lettre *e* en français afin d’être sûr de n’en manquer aucune. Une technique plus simple repose sur la **translittération**, une procédure qui consiste à transcrire un texte d’un alphabet (ou système d’écriture) vers un autre tout en respectant au mieux les sons et la signification des mots.\n",
    "\n",
    "En règle générale, il existe plusieurs systèmes de translittérations. Prenons l’exemple de la conversion de l’arabe vers le latin qui peut s’effectuer en respectant la norme ISO 233 ou la norme ALA-LC :\n",
    "\n",
    "أنتِ التي تحدّثين، أوّل الكلامِ.\n",
    "\n",
    "Cette phrase issue des *Mille et une nuits* se transcrit, en simplifiant légèrement :\n",
    "\n",
    "- أنتِ : \"Anti\" ;\n",
    "- التي : \"Allatī\" ;\n",
    "- تحدّثين : \"Tuhaddithīna\" ;\n",
    "- أوّل : \"Awwal\" ;\n",
    "- الكلامِ : \"Al-Kalām\".\n",
    "\n",
    "À quoi cela peut-il nous aider pour notre phrase remplie de diacritiques ? Et si on appliquait le principe de la translittération pour convertir d’un jeu de caractères vers un autre ? Quel jeu de caractères serait un bon candidat pour l’alphabet latin non accentué ?\n",
    "\n",
    "Essayons de transcrire notre phrase de l’UTF-8 vers l’ASCII :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2b53e-86a5-4fd2-acee-c3da171f9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"En pratique, un pêcheur pêche avec une canne.\" \\\n",
    "| iconv -f UTF-8 -t ASCII//TRANSLIT 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa334456-11dd-4802-9825-096467e16d9c",
   "metadata": {},
   "source": [
    "Où :\n",
    "\n",
    "- `-t ASCII//TRANSLIT` force la transcription vers l’ASCII selon un dictionnaire de translittération ;\n",
    "- `2>/dev/null` redirige les erreurs vers un périphérique spécial qui fait office de trou noir.\n",
    "\n",
    "Il reste à appliquer le filtre et à compter le nombre de lignes de résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74d0b8-fa89-4f69-87a2-8fb6aa662da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"En pratique, un pêcheur pêche avec une canne.\" \\\n",
    "| iconv -f UTF-8 -t ASCII//TRANSLIT 2>/dev/null \\\n",
    "| grep -io \"e\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dfa45e-9bd5-4aee-bd64-c0e2a5ce1f8c",
   "metadata": {},
   "source": [
    "#### Cas limite : exemple de la lettre *i* en turc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100958ab-b116-4684-b483-a7b95e2cdf1b",
   "metadata": {},
   "source": [
    "Le turc utilise quatre variantes de *i* :\n",
    "\n",
    "- *i* (minuscule avec point)\n",
    "- *ı* (minuscule sans point)\n",
    "- *İ* (majuscule avec point)\n",
    "- *I* (majuscule sans point)\n",
    "\n",
    "Une translittération de l’UTF-8 vers l’ASCII confond la lettre minuscule latine i sans point avec le chiffre *1* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163885c-b364-4148-8356-e3c842885857",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"İstanbul'da iki kişi ile ılık bir çay içtim.\" \\\n",
    "| iconv -f UTF-8 -t ASCII//TRANSLIT 2> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d44eaf8-5ad7-49f9-9949-2c1f31ca20d1",
   "metadata": {},
   "source": [
    "Dans ce cas, la seule alternative consiste à effectuer un pré-traitement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0632e24-3e97-479c-9210-132aa24efa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"İstanbul'da iki kişi ile ılık bir çay içtim.\" \\\n",
    "| tr 'ı' 'i' \\\n",
    "| iconv -f UTF-8 -t ASCII//TRANSLIT 2> /dev/null \\\n",
    "| grep -oi \"i\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a82e6e-8738-40e7-9855-452014453517",
   "metadata": {},
   "source": [
    "### Les classes de caractères Unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d0bc1-3b1d-4844-8076-8ae1b2329208",
   "metadata": {},
   "source": [
    "Avec les langues européennes, la complexité de la tâche reste contenue. Qu’en est-il avec, par exemple, des langues asiatiques ?\n",
    "\n",
    "Lorsqu’il s’agit de compter uniquement des correspondances particulières, aucune difficulté supplémentaire à signaler :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a17406-f696-4175-b130-86a3e74375d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"今日ははじめて、はっきりとわかった。\" \\\n",
    "| grep -o は | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac02ec7-4009-4c3c-b39d-517a0daa99bf",
   "metadata": {},
   "source": [
    "Le japonais est composé de plusieurs classes de caractères : les kanji, les katakana et les hiragana. Si l’objectif devient de comptabiliser tous les caractères d’une classe, il convient de faire appel à une option `-P` pour étendre les expressions rationnelles aux classes Unicode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a0b70-cf82-451b-88d5-ce9cb97590f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"今日ははじめて、はっきりとわかった。\" \\\n",
    "| grep -oP \"\\p{Script=Han}\" | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53bce7e-9bc1-4fbc-85cb-3bf2c0d00a5d",
   "metadata": {},
   "source": [
    "L’instruction précédente a repéré les caractères *今* et *日*, issus du script Han (Ensemble de caractères logographiques utilisés dans plusieurs systèmes d’écriture de langues asiatiques.). Notons que la syntaxe `\\p{Han}` peut, dans certains cas, conserver également les signes de ponctuation *、* et *。*. La recherche inclut alors tous les caractères définis comme Han, sans distinction de la catégorie \"script\".\n",
    "\n",
    "**Remarque :** La version BSD `grep` installée par défaut sur macOS ne supporte pas l’option `-P` pour les expressions compatibles Perl (PCRE). Il faut alors installer GNU `grep` et utiliser ensuite la commande `ggrep`.\n",
    "\n",
    "Ce comportement ouvre la possibilité de traiter des textes multilingues, comme par exemple repérer les citations en grec ou en latin dans un texte de Nietzsche.\n",
    "\n",
    "En plus des lettres d’un alphabet spécifique, on dénombre plusieurs classes Unicode :\n",
    "\n",
    "- `\\p{L}` : Toutes les lettres peu importe l’alphabet.\n",
    "- `\\p{N}` : Toutes les représentations de chiffres.\n",
    "- `\\p{P}` : Tous les symboles de ponctuation.\n",
    "- `\\p{S}` : Les symboles (mathématiques, monétaires et autres).\n",
    "- `\\p{Z}` : Tous les caractères d’espacement, incluant la tabulation, les sauts de ligne etc.\n",
    "- `\\p{C}` : Les caractères dits \"de contrôle\" comme les retours chariot, les sauts de ligne, etc.) et autres caractères invisibles.\n",
    "- `\\p{M}` : Les marques de diacritiques qui s’ajoutent aux lettres.\n",
    "- `\\p{Cased_Letter}` : Toutes les lettres majuscules et minuscules.\n",
    "- `\\p{Lower}` : Les lettre minuscules.\n",
    "- `\\p{Upper}` : Les lettres majuscules.\n",
    "\n",
    "**Remarque :** Sur macOS, les caractères Unicode sont généralement stockés sous la forme précomposée NFC (*Normalization Form Composed*), où les lettres accentuées et autres caractères combinés sont représentés sous une seule unité plutôt qu’en plusieurs composants distincts (ex: *é* au lieu de *e* + *´*). Pour cette raison, certaines expressions utilisant les classes Unicode ne répondront pas forcément de la manière attendue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63bdc4-3a74-418d-9ea9-68c219aa18c8",
   "metadata": {},
   "source": [
    "## Travailler avec des fréquences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc748c-97a9-4540-9b2c-5efb499e30fe",
   "metadata": {},
   "source": [
    "Les fréquences d’occurrences sont une première entrée dans la linguistique quantitative. Que l’on dénombre les mots-formes, les types, les lemmes, les étiquettes ou toute autre combinaison, elles servent à fournir certaines indications chiffrées sur un texte ou un corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ccc765-51b4-46f2-a471-cae3bf842387",
   "metadata": {},
   "source": [
    "### Fréquences cumulées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207734d-cb71-4a0a-879a-abd853790c17",
   "metadata": {},
   "source": [
    "La fréquence cumulée correspond à la somme des fréquences depuis le mot le plus fréquent jusqu’au rang considéré. Elle permet d’observer des phénomènes remarquables, comme le fait qu’un petit nombre de mots représente souvent une grande partie du texte. Dans la plupart des langues, les 100 mots les plus fréquents peuvent représenter jusqu’à 50 % des occurrences d’un texte, principalement en raison des mots grammaticaux (articles, prépositions, etc.).\n",
    "\n",
    "Sans analyse grammaticale, un tableau de la fréquence d’occurences de la phrase \"Le pêcheur pêche avec une canne à pêche\" donne :\n",
    "\n",
    "|Type|Fréquence|Fréquence cumulée absolue|Fréquence cumulée relative|\n",
    "|-|-|-|-|\n",
    "|pêche|2|2|0.250|\n",
    "|avec|1|3|0.375|\n",
    "|à|1|4|0.5|\n",
    "|canne|1|5|0.625|\n",
    "|le|1|6|0.750|\n",
    "|pêcheur|1|7|0.875|\n",
    "|un|1|8|1|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a9fc27-d64d-46aa-a9e9-de7eec75945c",
   "metadata": {},
   "source": [
    "### Poids relatif des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c825cfb3-e8dd-4f4e-9916-c9670af226a5",
   "metadata": {},
   "source": [
    "Le poids d’un mot-forme dans un texte peut être calculé de plusieurs manières :\n",
    "\n",
    "- Par sa fréquence relative (nombre d’occurrences divisé par le nombre total de mots).\n",
    "- Par son rang dans la liste des mots les plus fréquents.\n",
    "- Par une mesure de pondération comme son TF-IDF (*Term Frequency-Inverse Document Frequency*) qui prend en compte à la fois sa fréquence dans le document et sa rareté dans un corpus de référence.\n",
    "\n",
    "Ces mesures permettent de repérer les mots caractéristiques d’un texte, d’un auteur ou d’un genre particulier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d260784-8be2-4027-8552-0b8d6563e5f6",
   "metadata": {},
   "source": [
    "### Mots-clés, mots vides et listes d’exclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b1f388-a8d2-433f-af87-ff7fd95b9408",
   "metadata": {},
   "source": [
    "Dans un corpus, on ne voudra jamais analyser tous les mots. Soit notre attention se portera sur certains mots-clés à conserver, soit, au contraire, nous souhaiterons exclure certains résultats du calcul de fréquences. Parmi ces derniers, une catégorie particulière est réservée aux mots vides de sens (*stopwords* en anglais), qui sont des mots très fréquents dans une langue et qui, même s’ils remplissent une fonction grammaticale essentielle, apportent peu d’information sur le contenu sémantique d’un texte. Il s’agit principalement des déterminants, des prépositions, des pronoms et autres mots outils.\n",
    "\n",
    "L’identification et le filtrage de ces mots est une étape cruciale en analyse textuelle pour plusieurs raisons :\n",
    "\n",
    "- Ils peuvent représenter jusqu’à 50 % des occurrences dans un texte ;\n",
    "- ils faussent les statistiques de fréquence brute ;\n",
    "- ils créent du bruit dans l’analyse thématique ou la recherche d’information.\n",
    "\n",
    "Pour exclure un fichier contenant une liste de mots avant le comptage des fréquences, il convient d’intégrer un filtrage à la chaîne de traitement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08445758-ec15-47ae-bb49-0b11b302ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! grep -vwFf ./files/stopwords.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b27fe4-7cc2-42d9-ae59-cecea3d8f11b",
   "metadata": {},
   "source": [
    "Où :\n",
    "\n",
    "- `-v` (*invert match*) sert à exclure les résultats de l’expression rationnelle à suivre ;\n",
    "- `-w` assure que le moteur de filtre recherche des mots complets ;\n",
    "- `-F` contraint à effectuer une recherche sur des chaînes littérales ;\n",
    "- `-f` précise que ces chaînes proviennent d’un fichier.\n",
    "\n",
    "**Remarque :** Comme la commande `grep` agit sur une ligne, un filtrage trop précoce éliminera des pans entiers du texte à analyser si un seul des mots de la liste d’exclusion est détecté, ce qui sera probablement le cas pour les mots vides. Une bonne pratique consiste à tokeniser au préalable le texte en mettant un mot par ligne.\n",
    "\n",
    "En post-traitement, la commande sera appelée pour épurer la liste des fréquences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e5a8c-342d-4c77-ac85-86fedf5f0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude some words\n",
    "! grep -vwFf ./files/stopwords.txt ./files/frequencies.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cbd4bc-fdf0-45f1-88c6-c158b6f9e2cb",
   "metadata": {},
   "source": [
    "D’autres fois, pourtant, l’objet de recherche se concentrera sur l’emploi de ces mots grammaticaux. C’est le cas notamment dans les études qui impliquent une analyse stylistique : le style d’un·e auteur·rice se révèle souvent dans sa façon d’articuler et de composer les syntagmes entre eux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7da7c04-f472-4436-9edc-38322d85e24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords only\n",
    "! grep -wFf ./files/keywords.txt ./files/frequencies.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145640da-60c7-4ad8-8bc7-3f10c0c87d8b",
   "metadata": {},
   "source": [
    "### Rapport Type-Token (TTR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b478f32-36d2-4f10-a992-f6b722daf8fe",
   "metadata": {},
   "source": [
    "Le *Type-Token Ratio* (TTR) est un indicateur utilisé en linguistique quantitative pour évaluer la diversité lexicale d’un corpus. Il s’agit du rapport entre le nombre de types et le nombre de tokens dans un texte donné. Il s’exprime mathématiquement par la formule :\n",
    "\n",
    "$$\n",
    "\\text{TTR} = \\frac{\\text{Nombre de types}}{\\text{Nombre de tokens}}\n",
    "$$\n",
    "\n",
    "Un TTR élevé indique une grande diversité lexicale, ce qui est souvent le cas pour des textes littéraires riches ou des discours techniques variés. À l’inverse, un TTR faible peut refléter une répétition importante des mêmes mots, comme dans des textes didactiques ou des dialogues informels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa35a43-144f-4760-b7f0-75b05c10d909",
   "metadata": {},
   "source": [
    "#### Exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db534976-6dfa-4483-9e1d-57367fd171c9",
   "metadata": {},
   "source": [
    "Prenons le texte suivant :\n",
    "\n",
    ">\"Le chat mange le poisson et le chien aboie.\"\n",
    "\n",
    "**Tokens (9) :** \"Le\", \"chat\", \"mange\", \"le\", \"poisson\", \"et\", \"le\", \"chien\", \"aboie\".\n",
    "\n",
    "**Types (7) :** \"le\", \"chat\", \"mange\", \"poisson\", \"et\", \"chien\", \"aboie\".\n",
    "\n",
    "$$\n",
    "TTR = 7 \\div 9 \\approx 0,78\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de42896-423d-47e6-bf5e-3270d954ca4b",
   "metadata": {},
   "source": [
    "#### Traitement des mots grammaticaux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a4c63-72e9-4c12-90c5-96bde203c404",
   "metadata": {},
   "source": [
    "En règle générale, les mots grammaticaux sont exclus du calcul du TTR afin de se concentrer sur les mots porteurs de sens. Cette exclusion améliore la pertinence du ratio obtenu comme indicateur de la diversité lexicale. Si l’objectif en revanche est d’évaluer la richesse syntaxique, de comparer des registres de langue ou d’étudier des phénomènes spécifiques, il conviendra sans doute de les garder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0c9a9-ddaa-4249-9e38-f5aacfb6338a",
   "metadata": {},
   "source": [
    "#### Limites du TTR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6e75f3-67cd-477c-b769-9ee6e6cd0c91",
   "metadata": {},
   "source": [
    "Le TTR est sensible à la taille du corpus : plus un texte est long, plus il y a de chances que de nouveaux tokens soient des répétitions de types existants. Pour pallier cette limitation, il peut être utile de calculer le *Mean Segmental Type-Token Ratio* (MSTTR) qui consiste à diviser un texte en parties égales et à établir la moyenne des TTR des différentes parties, comme donné par la formule :\n",
    "\n",
    "$$\n",
    "\\text{MSTTR} = \\frac{\\sum_{i=1}^n \\text{TTR}_i}{n}\n",
    "$$\n",
    "\n",
    "La commande `split` permet de découper un fichier sur le critère du nombre de lignes :\n",
    "\n",
    "```sh\n",
    "split -l 1000 -d {file.txt} chunk_\n",
    "```\n",
    "\n",
    "Où :\n",
    "\n",
    "- `-l` impose de créer des fichiers de *n* lignes ;\n",
    "- `-d` force l’emploi de suffixes numériques dans la dénomination des fichiers ;\n",
    "- `chunk_` indique le préfixe à utiliser pour nommer les fichiers de sortie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5e1fe-6e00-4389-803c-3755390a4f31",
   "metadata": {},
   "source": [
    "### Distribution des longueurs de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6017230-87cf-41f6-a48f-9e1a5c401ab0",
   "metadata": {},
   "source": [
    "L’analyse de la longueur des mots offre un autre angle d’approche statistique. Elle permet de :\n",
    "\n",
    "- Caractériser le style d'un auteur (préférence pour les mots courts ou longs).\n",
    "- Comparer différents genres textuels (les textes techniques utilisent généralement des mots plus longs).\n",
    "- Identifier des motifs linguistiques propres à une langue (en allemand, les mots composés augmentent la moyenne).\n",
    "\n",
    "On peut représenter cette distribution sous forme d’histogramme ou calculer des indicateurs comme la longueur moyenne des mots, la médiane, ou l’écart-type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c31715-0e3f-4b8c-af3d-0a7237ab9c25",
   "metadata": {},
   "source": [
    "### Lois de distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c80be-9084-4cc7-9f3f-362b37c06210",
   "metadata": {},
   "source": [
    "Les fréquences lexicales suivent souvent des lois statistiques remarquables, notamment :\n",
    "\n",
    "- **La loi de Zipf :** la fréquence d’un mot est inversement proportionnelle à son rang.\n",
    "- **La loi de Mandelbrot :** une version affinée de la loi de Zipf qui tient compte de la structure hiérarchique du lexique.\n",
    "- **La loi de Heap :** relation entre la taille du vocabulaire et la taille du texte.\n",
    "\n",
    "Ces lois permettent de modéliser et de prédire le comportement des fréquences lexicales dans les textes en langage naturel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
