{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088c737f-a5b9-4d25-af99-11ea1b911152",
   "metadata": {},
   "source": [
    "# Le théorème de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1d664-3e73-4323-977b-34aaea677f55",
   "metadata": {},
   "source": [
    "L’un des principaux théorèmes de la théorie des probabilités est connu sous le nom de théorème de Bayes. Formulé en 1763 par Richard Price sur la base des travaux de feu le révérand Thomas Bayes qui lui avait légué ses travaux, il n’a eu de retentissement que bien plus tard, avec le progrès technologique, car son application réclamait d’opérer un grand nombre de calculs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d028b-e07b-408d-8363-40f3afe79b66",
   "metadata": {},
   "source": [
    "## Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a2885-431a-4958-ad9c-7f034d46bd4b",
   "metadata": {},
   "source": [
    "La formule originale du théorème est exprimée ainsi :\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $A$ et $B$ représentent deux événements.\n",
    "- $P(A|B)$ est la probabilité a posteriori (ou conditionnelle) de $A$ sachant $B$. Elle exprime notre degré de certitude sur $A$ après avoir pris en compte l’information apportée par $B$.\n",
    "- $P(B|A)$ représente la vraisemblance, c’est-à-dire la probabilité d’observer $B$ si $A$ est vrai.\n",
    "- $P(A)$ est la probabilité a priori de $A$, parfois appelée *prior*. Elle reflète notre degré de certitude initial (avant d’observer $B$).\n",
    "- $P(B)$ est la probabilité marginale de $B$, ou constante de normalisation. Elle correspond à la probabilité totale de $B$, calculée en tenant compte de tous les scénarios possibles où $B$ pourrait se produire. Elle garantit que $P(A|B)$ reste une probabilité valide (entre 0 et 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c72e3d2-629d-40b7-a0b9-050ed7607335",
   "metadata": {},
   "source": [
    "## Définition de la probabilité conditionnelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d2d2b-3c39-46f5-b7a8-d3821e0080dd",
   "metadata": {},
   "source": [
    "Par définition, la probabilité de réalisation d’un événement $B$ sachant que l’événement $A$ s’est produit ($P(A) \\neq 0$) est donnée par la formule :\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(A \\cap B)}{P(A)}\n",
    "$$\n",
    "\n",
    "Dans l’exemple d’un jeu de cartes réduit avec les trois figures (V, D, R) dans les quatre couleurs, nous pouvons estimer la probabilité qu’une carte soit un valet sachant qu’elle est noire (♣ ou ♠). Posons la formule :\n",
    "\n",
    "$$\n",
    "P(V|♣♠) = \\frac{P(♣♠ \\cap V)}{P(♣♠)}\n",
    "$$\n",
    "\n",
    "Dans un premier temps, déterminons la probabilité d’obtenir une carte noire :\n",
    "\n",
    "$$\n",
    "P(♣♠) = \\frac{F(♣♠)}{\\text{Card}(\\Omega)} = \\frac{6}{12} = \\frac{1}{2}\n",
    "$$\n",
    "\n",
    "Puis calculons la probabilité de tirer une carte qui soit à la fois un valet et de l’une des deux couleurs noires :\n",
    "\n",
    "$$\n",
    "P(♣♠ \\cap V) = \\frac{F(V♣) + F(V♠)}{\\text{Card}(\\Omega)} = \\frac{2}{12} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "Résolvons la formule posée plus haut :\n",
    "\n",
    "$$\n",
    "P(V|♣♠) = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7926ab8b-2923-4fc7-8727-ad0fd6d09c23",
   "metadata": {},
   "source": [
    "## Démonstration du théorème"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b8e297-48e9-47ca-9c93-f2cc04d9e1bc",
   "metadata": {},
   "source": [
    "Comme par définition nous avons :\n",
    "\n",
    "$$\n",
    "P(B|A) = \\frac{P(A \\cap B)}{P(A)}\n",
    "$$\n",
    "\n",
    "Alors :\n",
    "\n",
    "$$\n",
    "P(B|A) \\cdot P(A) = P(A \\cap B)\n",
    "$$\n",
    "\n",
    "Or, nous savons par symmétrie que :\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(B \\cap A)\n",
    "$$\n",
    "\n",
    "Donc, par égalisation, nous obtenons :\n",
    "\n",
    "$$\n",
    "P(B|A) \\cdot P(A) = P(A|B) \\cdot P(B)\n",
    "$$\n",
    "\n",
    "Et, par substitution :\n",
    "\n",
    "$$\n",
    "P(A|B) \\cdot P(B) = P(A \\cap B)\n",
    "$$\n",
    "\n",
    "Pour finir, en divisant par $P(B)$ :\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0483fed-8353-458d-b11f-d1133f2b71ff",
   "metadata": {},
   "source": [
    "## Étude de cas : un filtre anti-spam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1704eac-9b47-4faa-bfef-88f891a79069",
   "metadata": {},
   "source": [
    "Après avoir configuré un filtre anti-spam dont la tâche est de classer des emails dans deux catégories, *spam* ou *ham* pour les messages légitimes, l’évaluation a montré les résultats suivants :\n",
    "\n",
    "- un message sur 100 est un spam ;\n",
    "- le filtre est fiable à 99 % dans la détection des spams ;\n",
    "- le filtre détecte 95 % des messages légitimes.\n",
    "\n",
    "Nous voulons savoir, lorsqu’un filtre a détecté un spam, si le message concerné est réellement un spam. Nous posons les deux événements :\n",
    "\n",
    "- $A$ qui représente le cas où le message est réellement un spam ;\n",
    "- $B$ qui fait référence à un test positif.\n",
    "\n",
    "De là, nous pouvons formaliser la question en termes de probabilité conditionnelle : quelle est la probabilité qu’un message soit réellement un spam quand il a été détecté comme tel par le filtre ? Cela revient à calculer la formule de Bayes :\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Nous pouvons déjà résoudre le numérateur grâce aux données de l’énoncé, puisque :\n",
    "\n",
    "- $P(B|A)$ représente la probabilité que le filtre soit positif en présence d’un spam ;\n",
    "- $P(A)$ représente le proportion de spams dans les emails analysés.\n",
    "\n",
    "Nous avons ainsi :\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{0,99 \\cdot 0,01}{P(B)}\n",
    "$$\n",
    "\n",
    "Pour calculer $P(B)$, en l’absence de données supplémentaires, nous appliquons la formule des probabilités totales qui établit la relation suivante :\n",
    "\n",
    "$$\n",
    "P(B) = P(B|A) \\cdot P(A) + P(B|\\overline{A}) \\cdot P(\\overline{A})\n",
    "$$\n",
    "\n",
    "La probabilité qu’un test soit positif est la somme de deux probabilités :\n",
    "\n",
    "- celle issue du produit entre la probabilité que le filtre détecte un spam et la probabilité que le message soit un spam ;\n",
    "- celle issue du produit entre la probabilité que le filtre soit positif quand il n’est pas en présence d’un spam et la probabilité que le message ne soit pas un spam.\n",
    "\n",
    "Nous avons ainsi :\n",
    "\n",
    "$$\n",
    "P(B) = 0,99 \\times 0,01 + 0,05 \\times 0,99\n",
    "$$\n",
    "\n",
    "De là :\n",
    "\n",
    "$$\n",
    "P(A|B) = \\frac{0,99 \\cdot 0,01}{0,99 \\times 0,01 + 0,05 \\times 0,99} = \\frac{0,0099}{0,0594} = 0,1667\n",
    "$$\n",
    "\n",
    "En conclusion, un email détecté comme spam n’a que 16,7 % d’en être réellement un, une proportion somme toute assez faible alors que le filtre semblait très performant au vu des données de l’énoncé ! Cela illustre l’effet du faible taux de prévalence (seulement un spam sur cent messages) sur l’interprétation des résultats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
