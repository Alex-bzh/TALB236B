{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49bc4c7c-58b2-48d0-911d-966c2cdb1fd5",
   "metadata": {},
   "source": [
    "# La classification naïve bayésienne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1581bac1-ad3c-4c31-ac8e-9d9beafe767f",
   "metadata": {},
   "source": [
    "L’algorithme de classification naïve bayésienne, largement utilisé en intelligence artificielle, repose sur le théorème de Bayes pour prédire la classe d’une donnée tout en supposant l’indépendance de ses caractéristiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bee1dab-c70f-43c8-b142-786ec0d3e1e2",
   "metadata": {},
   "source": [
    "## Hypothèse d’indépendance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c75be1-a707-4748-8830-0463fd1fd648",
   "metadata": {},
   "source": [
    "### Une hypothèse bien naïve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bdce7f-8949-49ce-91fe-f641eca87471",
   "metadata": {},
   "source": [
    "La taille d’un chat a-t-elle une influence sur la longueur de son appendice caudal ? Le nombre d’heures de sommeil joue-t-il une quelconque importance dans l’état de vigilance d’une personne ? Le nombre d’enfants est-il en relation avec le type de la voiture qu’un foyer possède ?\n",
    "\n",
    "À raison, on aurait tendance à répondre positivement à toutes ces questions, mais pas un classificateur naïf bayésien. Pour lui, aucune caractéristique n’influence une autre. Bien que cette hypothèse soit irréaliste dans la plupart des cas, elle a prouvé sa solidité en termes de résultats. Qui plus est, elle permet de simplifier les calculs et d’obtenir des modèles légers et rapides, ce qui en fait une méthode particulièrement efficace lorsque la quantité de données est faible ou que les ressources technologiques sont limitées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8376a39-993e-4d4e-96d6-80bfd5d8c055",
   "metadata": {},
   "source": [
    "### Application à une tâche de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481834f-8432-4aed-959a-999ec06a9df0",
   "metadata": {},
   "source": [
    "Une tâche de classification a pour objectif d’associer à un objet une classe ($y$) en fonction de caractéristiques ($X$). On peut le traduire en termes de probabilités d’obtenir $y$ sachant $X$ :\n",
    "\n",
    "$$\n",
    "P(y \\mid X) = \\frac{P(X \\cap y)}{P(X)} = \\frac{P(X \\mid y) \\cdot P(y)}{P(X)}\n",
    "$$\n",
    "\n",
    "Comme $X$ est une matrice de facteurs ($x_1 \\,, x_2 \\,, \\dots \\,, x_n$) indépendants les uns des autres, la formule peut s’exprimer avec un produit de conditions indépendantes :\n",
    "\n",
    "$$\n",
    "P(y \\mid x_1 \\,, x_2 \\,, \\dots \\,, x_n) = \\frac{P (y) \\times \\prod_{i=1}^n P(x_{i} \\mid y)}{\\prod_{i=1}^n P(x_{i})}\n",
    "$$\n",
    "\n",
    "**Remarque :** Si les facteurs n’étaient pas jugés indépendants, la **règle du produit** qui exprime des probabilités conjointes sous forme de produits de probabilités conditionnelles entraînerait des calculs bien plus complexes :  \n",
    "$$\n",
    "P(x_1 \\,, x_2 \\,, \\dots \\,, x_n \\mid y) = P(x_1 \\mid y) \\times P(x_2 \\mid x_1 \\cap y) \\times P(x_3 \\mid x_1 \\cap x_2 \\cap y) \\times \\dots \\times P(x_n \\mid x_1 \\cap x_2 \\cap \\dots \\cap x_{n-1} \\cap, y)\n",
    "$$\n",
    "\n",
    "Et comme pour toutes les observations du jeu de données le dénominateur est constant, on peut le supprimer en inférant une notion de proportionnalité :\n",
    "\n",
    "$$\n",
    "P(y \\mid x_{1} \\,, x_{2} \\,, \\dots \\,, x_n) \\propto P (y) \\times \\prod_{i=1}^n P(x_{i} \\mid y)\n",
    "$$\n",
    "\n",
    "La fonction prédictive est appliquée à l’ensemble des classes possibles et le maximum a posteriori (MAP) sert ensuite à élire la classe la plus plausible :\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\operatorname*{argmax}_{y \\in \\{C_1, C_2, \\dots, C_K\\}} P(y) \\prod_{i=1}^n P(x_i \\mid y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91db3c1b-b24a-4287-8d48-581718e82e71",
   "metadata": {},
   "source": [
    "## Les types de classificateurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b1d63-f751-4c41-9cb9-3d2aabe14156",
   "metadata": {},
   "source": [
    "On distingue trois catégories de classificateurs :\n",
    "\n",
    "- **Le naïf bayésien multinomial :** utilisé principalement pour les données discrètes, comme la classification de texte où l’on comptabilise les occurrences de mots.\n",
    "- **Le naïf bayésien gaussien :** utilisé lorsque les données sont continues et supposent une distribution normale pour chaque caractéristique au sein de chaque classe. Si ce n’est pas le cas, une transformation peut être appliquée, voire un regroupement en classes, mais c’est au prix d’une perte sans doute conséquente d’information.\n",
    "- **Le naïf bayésien de Bernoulli :** adapté aux données binaires comme lorsque l’on signale la présence ou l’absence d’un mot plutôt que de compter ses occurrences.\n",
    "\n",
    "En pratique, il est rare qu’un jeu de données ne présente qu’un seul type de variables, aussi on adopte plutôt une approche hybride où chaque variable est modélisée conformément à sa distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8735935-dbae-481f-8433-52ae0bc2771d",
   "metadata": {},
   "source": [
    "## Étude de cas : classification de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a6c5f8-b407-4786-9b71-8bcc79d8639b",
   "metadata": {},
   "source": [
    "Imaginons une tâche de classification qui consiste à prédire la catégorie à laquelle un document appartient parmi trois catégories : *mystery*, *religion* ou *editorial*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436cd3d-a77e-4157-a295-ab316205832f",
   "metadata": {},
   "source": [
    "### Corpus d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1167f95b-95e4-4f7d-9ffa-d4c2b6bd378e",
   "metadata": {},
   "source": [
    "Ci-dessous, nous avons recueilli quelques statistiques sur des textes issus du Corpus *Brown* :\n",
    "\n",
    "| Index | TTR | >15-letter words | Quotes in foreign language? | Category |\n",
    "|-|-|-|-|-|\n",
    "| cl01 | 0,313816 | 1 | False | mystery   |\n",
    "| cl02 | 0,283544 | 2 | False | mystery   |\n",
    "| cl03 | 0,303542 | 0 | True  | mystery   |\n",
    "| cd01 | 0,335743 | 1 | True  | religion  |\n",
    "| cd02 | 0,314910 | 9 | False | religion  |\n",
    "| cd03 | 0,357204 | 3 | True  | religion  |\n",
    "| cb01 | 0,434545 | 3 | False | editorial |\n",
    "| cb02 | 0,410027 | 6 | False | editorial |\n",
    "| cb03 | 0,404635 | 2 | False | editorial |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2256a7-e6bb-437e-95b5-3389435ad91f",
   "metadata": {},
   "source": [
    "### Description des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ed42bb-6ebd-4fe4-9247-537f57c8a82c",
   "metadata": {},
   "source": [
    "Le premier réflexe face à un jeu de données est de décrire les variables qui le constituent :\n",
    "\n",
    "- **TTR** : *Type Token Ratio*, indicateur de diversité lexicale qui prend ses valeurs sur une échelle de $[0,1]$.\n",
    "- **>15-letter words :** Nombre de mots contenant plus de 15 lettres.\n",
    "- **Quotes in foreign language :** Le texte contient-il des citations en langue étrangère ?\n",
    "- **Category :** Catégorie du document.\n",
    "\n",
    "**Remarque :** Les données de la variable *Quotes in foreign language?* sont inventées.\n",
    "\n",
    "La variable *Category* est la **variable cible** (ou *target* en anglais). Dans le contexte d’une tâche de classification, elle consigne la classe du document. Toutes les autres variables, à l’exception de la variable *Index* que nous écartons, sont dites **explicatives** au sens où elles servent à expliquer l’attribution de la classe au document.\n",
    "\n",
    "Il est de bon ton ensuite d’explorer les données afin de vérifier leur intégrité (données manquantes ou aberrantes) puis de calculer quelques mesures de tendance centrale (moyenne, médiane…) et de dispersion (variance, écart-type…), le tout accompagné de diagrammes, afin d’en avoir une bonne vision d’ensemble. Nous en faisons ici l’économie pour nous concentrer sur la méthode pour établir correctement notre modèle de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35644bcf-766c-4dbf-b238-5a1539f101bc",
   "metadata": {},
   "source": [
    "### Document à classer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2ae20c-19f8-4ed4-af91-11a25e1083b1",
   "metadata": {},
   "source": [
    "Soit un nouveau document auquel nous souhaiterions attribuer l’étiquette la plus plausible en fonction des indicateurs suivants :\n",
    "\n",
    "- **TTR :** 0,410961 ;\n",
    "- **>15-letter words :** 4 ;\n",
    "- **Quotes in foreign language :** *True*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe43430-8420-4970-a0bd-0f2eff22807d",
   "metadata": {},
   "source": [
    "### Modéliser une variable binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3911cc2-1a07-405a-8e75-8087ffd95949",
   "metadata": {},
   "source": [
    "Attachons-nous en premier lieu à la variable *Quotes in foreign language*. Comme il s’agit d’une variable qui ne peut prendre que deux valeurs (*True* ou *False*), elle est dite **binaire** et, pour calculer la probabilité que notre document contienne de telles citations en langue étrangère, nous décidons de la modéliser comme si elle suivait une loi de Bernoulli où la probabilité conditionnelle dépend uniquement du nombre de réalisations de l’événement dans chaque classe :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  P(\\text{Quotes in foreign language} \\mid \\text{mystery}) &= \\dfrac{1}{3}\\\\\n",
    "  P(\\text{Quotes in foreign language} \\mid \\text{religion}) &= \\dfrac{2}{3}\\\\\n",
    "  P(\\text{Quotes in foreign language} \\mid \\text{editorial}) &= \\dfrac{0}{3}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Remarque :** Du nom du mathématicien suisse Jacques Bernoulli, la loi de Bernoulli modélise une variable aléatoire qui ne peut prendre que deux valeurs : 1 (succès) avec une probabilité $p$, et 0 (échec) avec une probabilité $1−p$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f08f934-ec27-49b6-bd01-a729a7c89711",
   "metadata": {},
   "source": [
    "### Modéliser une variable continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c99eaf1-8d8c-4974-ac5c-faa7fad56393",
   "metadata": {},
   "source": [
    "La variable *TTR* contient des données dites continues, dans le sens où elles peuvent prendre n’importe quelle valeur réelle sur un intervalle. Cette liberté empêche d’effectuer des calculs de fréquences, il serait en effet absurde de compter le nombre de fois où le *TTR* vaut 0,303542 ou 0,404635 ou encore 0,004569…\n",
    "\n",
    "S’il nous apparaît évident que la variable *TTR* ne suit pas une loi de Bernoulli comme dans le cas de la variable *Quotes in foreign language*, quelle loi choisir alors pour la modéliser ? Nous décidons arbitrairement de la traiter comme si elle suivait une loi normale et utilisons une modélisation gaussienne de la vraisemblance $P(x_{i} \\mid y)$, sous forme de fonction de densité :\n",
    "\n",
    "$$\n",
    "P(x_{i} \\mid y) \\propto \\frac{1}{\\sqrt{2 \\pi \\sigma^{2}_{y}}} \\exp \\left(- \\frac{\\left(x_{i} - \\mu_{y}\\right)^{2}}{2\\sigma^{2}_{y}} \\right)\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $x_i$ prend la valeur de la variable $x$ pour une observation donnée ;\n",
    "- $\\mu_y$ représente l’espérance de la variable conditionnelle à $y$ (moyenne arithmétique des observations associées à la classe $y$) ;\n",
    "- $\\sigma^2_y$ représente la variance non biaisée de l’échantillon en mesurant la dispersion des valeurs de $y$ autour de la moyenne.\n",
    "\n",
    "**Remarque :** Si dans la réalité nous devrions vérifier d’abord l’hypothèse de normalité de la variable avant de l’exploiter, nous supposons ici à des fins pédagogiques que les données forment un échantillon d’une distribution gaussienne. Dans le cas contraire, nous aurions eu le choix entre deux alternatives : soit la transformer, avec par exemple un logarithme, soit effectuer des regroupements pour en faire une variable catégorielle. Notons en dernier lieu que le *Type Token Ratio* a très peu de chances de suivre une loi normale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117699fa-6792-4111-9715-2c93a153cfc3",
   "metadata": {},
   "source": [
    "#### Calculer l’espérance mathématique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cf87c7-763e-4f71-b2cd-e6254aeb2887",
   "metadata": {},
   "source": [
    "Nous évaluons l’espérance de la variable *TTR* à la moyenne de ses valeurs :\n",
    "\n",
    "$$\n",
    "\\bar{y} = \\frac{1}{n} \\sum_{i=1}^{n} y_i\n",
    "$$\n",
    "\n",
    "Ce qui donne, pour chaque catégorie :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\bar{y}_\\text{mystery} &= \\frac{1}{3} \\cdot 0,900902 = 0,3003\\\\\n",
    "\\bar{y}_\\text{religion} &= \\frac{1}{3} \\cdot 1,007857 = 0,33595\\\\\n",
    "\\bar{y}_\\text{editorial} &= \\frac{1}{3} \\cdot 1,249207 = 0,4164\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16368179-a146-4a33-95aa-6b3020e08a48",
   "metadata": {},
   "source": [
    "#### Calculer la variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83745286-06e4-4e12-b471-b2e78be1d37d",
   "metadata": {},
   "source": [
    "La variance se définit comme l’espérance des écarts d’une variable $X$ à la moyenne réelle de la population. Dans le cas où l’on calcule la variance d’un échantillon, il est de coutume d’appliquer un degré de liberté de 1 afin d’obtenir un estimateur non biaisé :\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n",
    "$$\n",
    "\n",
    "La variance de la variable *TTR* vaut ainsi, pour chaque catégorie :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sigma^2_\\text{mystery} &= \\frac{1}{3-1} \\cdot ((0,313816 - 0,3003)^2 + (0,283544 - 0,3003)^2 + (0,303542 - 0,3003)^2)\\\\\n",
    "&= \\frac{1}{2} \\cdot (0,00018268 + 0,00028076 + 0,00001051)\\\\\n",
    "&= 0,00023698\\\\\n",
    "\\sigma^2_\\text{religion} &= \\frac{1}{3-1} \\cdot ((0,335743 - 0,33595)^2 + (0,314910 - 0,33595)^2 + (0,357204 - 0,33595)^2)\\\\\n",
    "&= \\frac{1}{2} \\cdot (0,00000004 + 0,00044268 + 0,00045173)\\\\\n",
    "&= 0,00044722\\\\\n",
    "\\sigma^2_\\text{editorial} &= \\frac{1}{3-1} \\cdot ((0,434545 - 0,4164)^2 + (0,410027 - 0,4164)^2 + (0,404635 - 0,4164)^2)\\\\\n",
    "&= \\frac{1}{2} \\cdot (0,00032924 + 0,00004062 + 0,00013842)\\\\\n",
    "&= 0,00025414\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154f7577-7430-4215-aa7a-838e3d4b0293",
   "metadata": {},
   "source": [
    "#### Estimer la probabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d43b34-8e91-465a-946a-7a4dfe4a9ff5",
   "metadata": {},
   "source": [
    "En remplaçant les termes de la fonction de densité de probabilité, nous obtenons :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\text{TTR = 0,410961} \\mid \\text{mystery}) &\\propto \\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot 0,00023698}} \\exp \\left(- \\frac{\\left(0,410961 - 0,3003\\right)^{2}}{2 \\cdot 0,00023698} \\right)\\\\\n",
    "&\\propto 1,55 \\times 10^{-10}\\\\\n",
    "P(\\text{TTR = 0,410961} \\mid \\text{religion}) &\\propto \\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot 0,00044722}} \\exp \\left(- \\frac{\\left(0,410961 - 0,33595\\right)^{2}}{2 \\cdot 0,00044722} \\right)\\\\\n",
    "&\\propto 0,0349\\\\\n",
    "P(\\text{TTR = 0,410961} \\mid \\text{editorial}) &\\propto \\frac{1}{\\sqrt{2 \\cdot \\pi \\cdot 0,00025414}} \\exp \\left(- \\frac{\\left(0,410961 - 0,4164\\right)^{2}}{2 \\cdot 0,00025414} \\right)\\\\\n",
    "&\\propto 23,62\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90cb40-55f9-4730-9387-d431f7be2ba1",
   "metadata": {},
   "source": [
    "#### Interprétation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb68d0a-c660-425c-858d-f7bc225f9ad6",
   "metadata": {},
   "source": [
    "La densité de probabilité associée à un *TTR* de 0,410961 pour la catégorie *mystery* est très faible, un résultat qui s’explique par un écart plutôt important de la moyenne alors même que l’écart-type (la racine carrée de la variance) est lui-même minime.\n",
    "\n",
    "Pour la catégorie *religion*, bien que le *TTR* soit également éloigné de la moyenne, un écart-type plus grand permet d’en atténuer l’impact, ce qui se traduit par une densité de probabilité plus élevée.\n",
    "\n",
    "Enfin, la densité maximale est obtenue pour la catégorie *editorial* : le *TTR* du nouveau document est très proche de la moyenne de cette classe alors même que nous savons sa variance marginale.\n",
    "\n",
    "Si nous traçons les courbes de densité par classe, nous observons bien que la densité pour la classe *editorial* est très élevée alors que les autres sont proches de 0 :\n",
    "\n",
    "![Un intervalle de ± 0,001 autour du TTR observé (0,410961) croise les courbes de densité pour les trois classes à des hauteurs différentes. La densité pour la classe *editorial* est la plus élevée des trois.](./figs/TTR_densities.png)\n",
    "\n",
    "Affichage des courbes de densité par classes. La densité pour le TTR observé (0,410961) est la plus élevée pour la classe 'editorial'.\n",
    "\n",
    "Le résultat obtenu est une densité et non une probabilité qui, elle, pour rappel, s’exprime dans un intervalle $[0,1]$. Pour obtenir une probabilité, nous pouvons utiliser une fonction de répartition d’une loi normale (CDF pour *Cumulative Distribution Function*) ou simplement consulter la table de la loi normale.\n",
    "\n",
    "Par exemple, pour estimer la probabilité qu’un *TTR* pour la classe *editorial* tombe dans un intervalle autour de 0.410961 ± 0.001 sachant que $\\mu_{\\text{editorial}} = 0.4164$ et $\\sigma_{\\text{editorial}} = \\sqrt{0.00025414} \\approx 0.01593$ nous posons :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  P(0.410961 - 0.001 < TTR < 0.410961 + 0.001) &\\approx \\Phi(−0,278) − \\Phi(−0,404) \\\\\n",
    "  &\\approx 0.3903 − 0.3438 \\\\\n",
    "  &= 0.0465\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "De là, la probabilité de tomber sur un TTR à ± 0.001 autour de 0.410961 est de 4,65 % pour la classe *editorial*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608ba23-2cee-4b85-a581-b80194c82ae5",
   "metadata": {},
   "source": [
    "### Modéliser une variable discrète"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f007380-1a1e-49af-b6e3-dd67bf2a5f27",
   "metadata": {},
   "source": [
    "La variable *>15-letter words* est représentée par des valeurs discrètes qui prennent l’apparence de nombres entiers et strictement positifs. Comme en plus elle rend compte d’un événement rare, les mots de plus de quinze lettres dans un texte anglais étant peu fréquents, on a tout intérêt à la traiter comme une distribution de Poisson (asymétrie à droite car il est plus fréquent de rencontrer très peu de mots de plus de quinze lettres).\n",
    "\n",
    "![La distribution des mots de plus de quinze lettres dans le corpus Brown montre une asymétrie à droite caractéristique d’une loi de Poisson.](./figs/words_distribution.png)\n",
    "\n",
    "La distribution des mots de plus de quinze lettres dans le corpus Brown montre une asymétrie à droite caractéristique d’une loi de Poisson.\n",
    "\n",
    "Dans ce cas, nous considérons la fonction de masse de probabilité de Poisson :\n",
    "\n",
    "$$\n",
    "P(X = k) = \\frac{\\lambda^k \\cdot e^{-\\lambda}}{k!}\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- $k$ est le nombre de mots de plus de 15 lettres observé ;\n",
    "- $\\lambda$ est le taux moyen d’occurrence observé pour la catégorie.\n",
    "\n",
    "Calculons d’abord $\\lambda$ pour chaque catégorie :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\lambda_{mystery} &= \\frac{1 + 2 + 0}{3} = 1\\\\\n",
    "\\lambda_{religion} &= \\frac{1 + 9 + 3}{3} = 4,33\\\\\n",
    "\\lambda_{editorial} &= \\frac{3 + 6 + 2}{3} = 3,67\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "À présent, calculons la probabilité que notre document appartienne à une catégorie particulière :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\text{>15-letter words = 4} \\mid \\text{mystery}) &= \\frac{1^4 \\cdot e^{-1}}{4!}\\\\\n",
    "&= \\frac{1 \\cdot 0,3679}{24}\\\\\n",
    "&= 0,0153\\\\\n",
    "P(\\text{>15-letter words = 4} \\mid \\text{religion}) &= \\frac{4,33^4 \\cdot e^{-4,33}}{4!}\\\\\n",
    "&= \\frac{351,52125121 \\cdot 0,013}{24}\\\\\n",
    "&\\approx 0,1904\\\\\n",
    "P(\\text{>15-letter words = 4} \\mid \\text{editorial}) &= \\frac{3,67^4 \\cdot e^{-3,67}}{4!}\\\\\n",
    "&= \\frac{181,41126721 \\cdot 0,025}{24}\\\\\n",
    "&\\approx 0,189\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c82ad-3b01-41fc-a429-720285621ce3",
   "metadata": {},
   "source": [
    "### Modèle de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e9c9bc-8ea4-4af4-b32a-16bc8c1412ec",
   "metadata": {},
   "source": [
    "Maintenant que nous connaissons toutes les probabilités pour chaque variable, nous pouvons calculer la vraisemblance selon laquelle notre document appartienne à une catégorie ou l’autre. En nous fondant sur le théorème de Bayes, nous pouvons établir le modèle suivant :\n",
    "\n",
    "$$\n",
    "P(y \\mid X) \\propto P(y) \\cdot P(X_{\\text{TTR}} \\mid y) \\cdot P(X_{\\text{>15-letter words}} \\mid y) \\cdot P(X_{\\text{Quotes in foreign language}} \\mid y)\n",
    "$$\n",
    "\n",
    "Et puisque le prior $P(y)$ est le même pour les trois classes ($\\frac{1}{3}$), la vraisemblance $P(X \\mid y)$ suffit à elle seule pour le calcul de la probabilité a posteriori, à un facteur de normalisation près. Pour nos trois classes, nous obtenons les scores suivants :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\text{mystery} \\mid X) &\\propto 1,55 \\times 10^{-10} \\cdot 0,0153 \\cdot \\frac{1}{3}\\\\\n",
    "&\\propto 7,905 \\times 10^{-13}\\\\\n",
    "P(\\text{religion} \\mid X) &\\propto 0,0349 \\cdot 0,1904 \\cdot \\frac{2}{3}\\\\\n",
    "&\\propto 0,0044\\\\\n",
    "P(\\text{editorial} \\mid X) &\\propto 23,62 \\cdot 0,189 \\cdot \\frac{0}{3}\\\\\n",
    "&\\propto 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "À ce stade, nous pouvons conclure que :\n",
    "\n",
    "$$\n",
    "P(\\text{religion} \\mid X) > P(\\text{mystery} \\mid X) > P(\\text{editorial} \\mid X)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a8d178-6a42-4fbb-aedb-d2400ce63049",
   "metadata": {},
   "source": [
    "#### Lissage de Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55e668-9233-4efd-9e4a-20f57f289e3f",
   "metadata": {},
   "source": [
    "Un problème classique avec la classification naïve bayésienne est que si l’une des probabilités conditionnelles (ou l’un des scores de vraisemblance comme dans notre cas) est égale à 0, alors tout le produit $P(X \\mid y_i)$ est annulé et ce même si les autres termes sont significatifs.\n",
    "\n",
    "Pour éviter ce genre d’écueil, il est courant d’utiliser une méthode de lissage qui consiste à ajouter une petite valeur à chaque donnée. L’une de ces méthodes s’appelle **lissage de Laplace** : on rajoute un paramètre $\\alpha$ au numérateur que l’on ajoute également au dénominateur mais en le multipliant par le nombre $k$ de valeurs possibles. Dans le cas de la variable *Quotes in foreign language?*, en prenant $\\alpha = 1$ cela donne :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\text{mystery} \\mid X) &\\propto 1.55 \\times 10^{-10} \\cdot 0.0153 \\cdot \\frac{1 + 1}{3 + 1 \\cdot 2}\\\\\n",
    "&\\propto 1.55 \\times 10^{-10} \\cdot 0.0153 \\cdot \\frac{2}{5}\\\\\n",
    "&\\propto 9.486 \\times 10^{-13}\\\\\n",
    "P(\\text{religion} \\mid X) &\\propto 0.0349 \\cdot 0.1904 \\cdot \\frac{2 + 1}{3 + 1 \\cdot 2}\\\\\n",
    "&\\propto 0.0349 \\cdot 0.1904 \\cdot \\frac{3}{5}\\\\\n",
    "&\\propto 0.004\\\\\n",
    "P(\\text{editorial} \\mid X) &\\propto 23.62 \\cdot 0.189 \\cdot \\frac{0 + 1}{3 + 1 \\cdot 2}\\\\\n",
    "&\\propto 23.62 \\cdot 0.189 \\cdot \\frac{1}{5}\\\\\n",
    "&\\propto 0.893\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Nous pouvons conclure que, après application du lissage de Laplace, la classe la plus plausible pour le document dont les paramètres sont $[0,410961, 4, \\text{True}]$ est la classe *editorial* avec un score de 0,893."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab76e70-19f9-4455-b566-59794c874ae0",
   "metadata": {},
   "source": [
    "#### Normalisation des scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ba8c82-6c8f-4001-8b94-382400b06597",
   "metadata": {},
   "source": [
    "Le score obtenu n’est pas à proprement parler une probabilité puisqu’il mélange une densité (pour la variable *TTR*) et des probabilités. Cela ne pose toutefois pas de problème comme notre modèle adopte une **approche naïve bayésienne mixte** qui assume l’idée d’obtenir des scores non normalisés afin de ne sélectionner que le plus élevé.\n",
    "\n",
    "Si nous souhaitons normaliser les scores, nous n’avons plus qu’à appliquer le théorème de Bayes. Comme nous connaissons $P(X \\mid \\text{editorial})$, nous pouvons facilement calculer $P(\\text{editorial} \\mid X)$ :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\text{editorial} \\mid X) &= \\frac{P(X \\mid \\text{editorial}) \\cdot P(\\text{editorial})}{P(X)}\\\\\n",
    "&= \\frac{0.893 \\cdot 0.33}{P(X)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Pour obtenir $P(X)$, nous utilisons la formule des probabilités totales :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(X) &= P(X \\mid \\text{editorial}) \\cdot P(\\text{editorial}) + P(X \\mid \\text{mystery}) \\cdot P(\\text{mystery}) + P(X \\mid \\text{religion}) \\cdot P(\\text{religion})\\\\\n",
    "&= 0.893 \\cdot 0.33 + 0.004 \\cdot 0.33 + 9.486 \\times 10^{-13} \\cdot 0.33\\\\\n",
    "&= 0.295 + 0.00132 + 3.13 \\times 10^{-13}\\\\\n",
    "&= 0.296\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "De là, nous pouvons résoudre :\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(\\text{mystery} \\mid X) &= \\frac{9.486 \\times 10^{-13} \\cdot 0.33}{0.296} = 1.057 \\times 10^{-12}\\\\\n",
    "P(\\text{religion} \\mid X) &= \\frac{0.004 \\cdot 0.33}{0.296} = 0.0045\\\\\n",
    "P(\\text{editorial} \\mid X) &= \\frac{0.893 \\cdot 0.33}{0.296} = 0.9966\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Au final, nous pouvons conclure qu’il y a 99,66 % de chances que le nouveau document à classer appartienne à la catégorie *editorial*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
